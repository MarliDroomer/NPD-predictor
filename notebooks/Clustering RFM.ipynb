{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering RFM\n",
    "This notebook performs clustering on the Instacart Dataset to segment users based on the Recency, Frequency and Monetary values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering the data for customer segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the necessary packages \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "%matplotlib inline \n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to test KMeans at various k\n",
    "# This approach uses silhouette score to evaluate KMeans\n",
    "def optimal_kmeans(dataset, start=2, end=11):\n",
    "    '''\n",
    "    Calculate the optimal number of kmeans\n",
    "    \n",
    "    INPUT:\n",
    "        dataset : dataframe. Dataset for k-means to fit\n",
    "        start : int. Starting range of kmeans to test\n",
    "        end : int. Ending range of kmeans to test\n",
    "    OUTPUT:\n",
    "        Values and line plot of Silhouette Score.\n",
    "    '''\n",
    "    \n",
    "    # Create empty lists to store values for plotting graphs\n",
    "    n_clu = []\n",
    "    km_ss = []\n",
    "\n",
    "    # Create a for loop to find optimal n_clusters\n",
    "    for n_clusters in range(start, end):\n",
    "\n",
    "        # Create cluster labels\n",
    "        kmeans = KMeans(n_clusters=n_clusters)\n",
    "        labels = kmeans.fit_predict(dataset)\n",
    "\n",
    "        # Calcualte model performance\n",
    "        silhouette_avg = round(silhouette_score(dataset, labels, \n",
    "                                                random_state=1), 3)\n",
    "\n",
    "        # Append score to lists\n",
    "        km_ss.append(silhouette_avg)\n",
    "        n_clu.append(n_clusters)\n",
    "\n",
    "        print(\"No. Clusters: {}, Silhouette Score: {}, Change from Previous Cluster: {}\".format(\n",
    "            n_clusters, \n",
    "            silhouette_avg, \n",
    "            (km_ss[n_clusters - start] - km_ss[n_clusters - start - 1]).round(3)))\n",
    "\n",
    "        # Plot graph at the end of loop\n",
    "        if n_clusters == end - 1:\n",
    "            plt.figure(figsize=(5.6,3.5))\n",
    "\n",
    "            #plt.title('Silhouette Score Elbow for KMeans Clustering')\n",
    "            plt.xlabel('k')\n",
    "            plt.ylabel('silhouette score')\n",
    "            sns.pointplot(x=n_clu, y=km_ss)\n",
    "            plt.savefig('silhouette_score.pdf', format='pdf',\n",
    "                        pad_inches=2.0)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def kmeans(df, clusters_number):\n",
    "    '''\n",
    "    Implement k-means clustering on dataset\n",
    "    \n",
    "    INPUT:\n",
    "        dataset : dataframe. Dataset for k-means to fit.\n",
    "        clusters_number : int. Number of clusters to form.\n",
    "        end : int. Ending range of kmeans to test.\n",
    "    OUTPUT:\n",
    "        Cluster results and t-SNE visualisation of clusters.\n",
    "    '''\n",
    "    x = 25000\n",
    "    kmeans = KMeans(n_clusters = clusters_number, random_state = 1)\n",
    "    kmeans.fit(df[:x])\n",
    "    \n",
    "    labels = kmeans.predict(df[x:])\n",
    "    # Extract cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "        \n",
    "    # Create a cluster label column in original dataset\n",
    "    df_new = df[:x].assign(Cluster = cluster_labels)\n",
    "    \n",
    "#     # Initialise TSNE\n",
    "#     model = TSNE(random_state=1)\n",
    "#     transformed = model.fit_transform(df)\n",
    "    \n",
    "#     # Plot t-SNE\n",
    "#     plt.title('Flattened Graph of {} Clusters'.format(clusters_number))\n",
    "#     sns.scatterplot(x=transformed[:,0], y=transformed[:,1], hue=cluster_labels, style=cluster_labels, palette=\"Set1\")\n",
    "#     plt.savefig('cluster_brain_plot_6_clusters_first_2500.png')\n",
    "    \n",
    "    \n",
    "    return df_new, cluster_labels, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('axes', labelsize=11)\n",
    "plt.rc('axes', titlesize=11)\n",
    "plt.rc('xtick', labelsize=9)\n",
    "plt.rc('ytick', labelsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and merge the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"../instacart/products.csv\")\n",
    "orders = pd.read_csv(\"../instacart/orders.csv\")\n",
    "order_products_train = pd.read_csv(\"../instacart/order_products__train.csv\")\n",
    "order_products_prior = pd.read_csv(\"../instacart/order_products__prior.csv\")\n",
    "departments = pd.read_csv(\"../instacart/departments.csv\")\n",
    "aisles = pd.read_csv(\"../instacart/aisles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = products.merge(order_products_prior, on = 'product_id', how = 'inner')\n",
    "merge_data = departments.merge(merge_data, on = 'department_id', how = 'inner')\n",
    "merge_data = orders.merge(merge_data, on = 'order_id', how = 'inner')\n",
    "\n",
    "#remove some useless info\n",
    "# merge_data = merge_data.drop(['department','product_name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Number of departments:\", departments['department_id'].nunique())\n",
    "print( \"Number of aisles:\", aisles['aisle_id'].nunique())\n",
    "print( \"Number of products:\", products['product_id'].nunique())\n",
    "print( \"Number of unique users:\", merge_data['user_id'].nunique())\n",
    "print( \"Number of unique orders\", merge_data['order_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Departments columns:\", departments.columns)\n",
    "print(\"Aisles columns:\", aisles.columns)\n",
    "print(\"Product columns:\", products.columns)\n",
    "print(\"Order_products:\" , order_products_prior.columns)\n",
    "print(\"Order:\" , orders.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to calculate the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns data of User A\n",
    "def user_specific_data(user_number):\n",
    "    \n",
    "    user_data = merge_data_train[merge_data_train['user_id'] == user_number]\n",
    "    \n",
    "    return user_data\n",
    "\n",
    "# returns data of User A and Item B\n",
    "def user_product_data(user_number,product_number):\n",
    "    \n",
    "    user_data = merge_data[merge_data['user_id'] == user_number]\n",
    "    user_product_data = user_data[user_data['product_id'] == product_number]\n",
    "    \n",
    "    \n",
    "    return user_product_data\n",
    "\n",
    "#creating crosstabs that indicates the items purchased during each transaction also giving the days since prior-order.\n",
    "#Visually easy to see which item where purchased in a transaction.\n",
    "def crosstab_user(user_number):\n",
    "    \n",
    "    user_data = user_specific_data(user_number)\n",
    "    seq = user_data.order_id.unique()\n",
    "    crosst_user = pd.crosstab(user_data.product_name,user_data.order_id).reindex(seq, axis = 'columns')\n",
    "    sns.heatmap(crosst_user,cmap=\"YlGnBu\",annot=True, cbar=False)\n",
    "    \n",
    "    return crosst_user\n",
    "\n",
    "\n",
    "def crosstab_user_order_id(user_number):\n",
    "    \n",
    "    user_data = user_specific_data(user_number)\n",
    "    user_data = user_data.fillna(value = 0, axis = 1)\n",
    "    seq = user_data.order_id.unique()\n",
    "    dspo_data = user_data.groupby('order_id', as_index=False)['days_since_prior_order'].mean()\n",
    "    #dspo_data = dspo_data.T\n",
    "    #user_data = pd.concat([dspo_data,user_data])\n",
    "        \n",
    "    crosst_user = pd.crosstab(user_data.product_name,user_data.order_id).reindex(seq, axis = 'columns')\n",
    "    #sns.heatmap(crosst_user,cmap=\"YlGnBu\",annot=True, cbar=False)\n",
    "    \n",
    "    crosst_user = pd.merge((crosst_user.T), dspo_data, on = 'order_id')\n",
    "    crosst_user = crosst_user.set_index('order_id')\n",
    "    crosst_user = crosst_user.T\n",
    "    #sns.heatmap(crosst_user,cmap=\"YlGnBu\",annot=True, cbar=False)\n",
    "        \n",
    "    return crosst_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency being the number of orders placed by a user\n",
    "\n",
    "# Total number of orders placed by a specific user\n",
    "order_id_grouped = merge_data.drop(['days_since_prior_order','product_id','product_name','add_to_cart_order','reordered'],axis = 1)\n",
    "number_of_orders_per_user = order_id_grouped.groupby('user_id').agg(num_orders = pd.NamedAgg(column = 'order_id', aggfunc = 'nunique' ))\n",
    "number_of_orders_per_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the number of products in each order\n",
    "#creating a graph displaying the time of the day vs the departments\n",
    "dep_prod = products.merge(departments, on = 'department_id', how = 'inner')\n",
    "order_order_prod = orders.merge(order_products_prior, on = 'order_id', how = 'inner')\n",
    "order_dep_prod = dep_prod.merge(order_order_prod,on = 'product_id', how = 'inner')\n",
    "order_dep_prod_cleaned = order_dep_prod.drop(['days_since_prior_order','add_to_cart_order','reordered','aisle_id','product_id','product_name','order_id','user_id','eval_set'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prods = order_dep_prod.groupby(\"order_id\")[\"add_to_cart_order\"].aggregate(\"max\").reset_index()\n",
    "cnt_srs = num_prods.add_to_cart_order.value_counts()\n",
    "cnt_srs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe that specify the number of products in each order for each user\n",
    "\n",
    "num_prods_user = orders.merge(num_prods, on = 'order_id', how = 'inner')\n",
    "num_prods_user.drop(['eval_set','order_dow','order_hour_of_day','days_since_prior_order','order_number'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the average products per order per user for the monetary entry of RFM\n",
    "average_num_prods_user =num_prods_user.groupby(\"user_id\")[\"add_to_cart_order\"].aggregate(\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe that contains the Frequency en the monatory values\n",
    "\n",
    "F_M = number_of_orders_per_user.merge(average_num_prods_user, on = 'user_id', how = 'inner')\n",
    "F_M = F_M.rename(columns={\"num_orders\": \"Frequency\", \"add_to_cart_order\": \"Monetary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the Recency feature\n",
    "# getting the last days_since_prior_order in the train set....\n",
    "\n",
    "# using the 2nd last days_since_prior_order as recency\n",
    "last_days_since_prior_order_user =orders.groupby(\"user_id\")[\"days_since_prior_order\"].nth(-2).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "# using the average days_since_prior_order as the recency feature\n",
    "mean_days_since_prior_order_user =orders.groupby(\"user_id\")[\"days_since_prior_order\"].mean().reset_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_F_M = F_M.merge(mean_days_since_prior_order_user, on = 'user_id', how = 'inner')\n",
    "RFM = R_F_M.rename(columns={\"days_since_prior_order\": \"Recency\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFM.set_index('user_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the columns so that the order of the columns are RFM \n",
    "cols = ['Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "RFM = RFM[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the data created is skewed...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFM = pd.read_pickle(\"RFM.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the data to see if the features that we created is skewed\n",
    "plt.figure(figsize=[5.6,5.6])\n",
    "RFM.hist(figsize=[5.6,4])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"RFM.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the features we see that the Monetary feature that was created is positively skewed. \n",
    "\n",
    "This means that we will have to transform the current data to the log form of the data. \n",
    "\n",
    "The orthers are roughly normal, so that we will use it as is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the figures we see that Frequency (total number of orders per customer) is positively skewed\n",
    "#thus we need to log transform the data so that we can use K-Means clustering \n",
    "\n",
    "RFM['Frequency'] = np.log(RFM['Frequency'])\n",
    "#RFM['Recency'] = np.log(RFM['Recency'])\n",
    "#RFM['Monerary'] = np.log(RFM['Monerary'])\n",
    "\n",
    "\n",
    "# RFM.hist(figsize=(10,6))\n",
    "# plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFM['Monetary'] = np.log(RFM['Monetary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = RFM.drop(['Recency'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=[5.6,2])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rfm_scaled.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data looks more normal so we will use it as created... \n",
    "\n",
    "The data should also be scaled..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now that the data is roughly normal we need to scale the features, because K-Means wants normal data\n",
    "#around a mean of 0 and a std of 1\n",
    "\n",
    "#Scaling the RFM features that we created\n",
    "#This is part of the pre-processing process...\n",
    "scaling_fact = StandardScaler()\n",
    "RFM_scaled = scaling_fact.fit_transform(RFM)\n",
    "\n",
    "RFM_scaled = pd.DataFrame(RFM_scaled)\n",
    "RFM_scaled.hist(figsize=(10,6))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_described = RFM_scaled.describe()\n",
    "data_described = data_described.round(decimals=2)\n",
    "data_described"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Segmentation\n",
    "### Using K-Means to cluster into segments after engineering RFM features\n",
    "\n",
    "Looking into how many clusters are a good number for this dataset\n",
    "\n",
    "K-Means performs best when not skewed and when normalised around a mean of 0 and a standard deviation of 1 -- we just did these so we are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance of KMeans at various values k\n",
    "# This approaches uses distortion score to evaluate KMeans\n",
    "model = KMeans()\n",
    "plt.figure(figsize= [5.6,3])\n",
    "visualizer = KElbowVisualizer(model, k=(2, 15))\n",
    "\n",
    "visualizer.fit(RFM_scaled)   \n",
    "# plt.tight_layout()\n",
    "# \n",
    "visualizer.show(outpath = \"elbow.pdf\")\n",
    "# plt.savefig('elbow.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_xlabel(\"k\")\n",
    "plt.gca().set_ylabel(\"distortion score\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.savefig('elbow.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.fit(RFM_scaled) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the elbow method it is clear that the number of clusters should be 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot clusters for k=3\n",
    "cluster_less_6, cluster_labels, labels = kmeans(RFM_scaled, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels.shape)\n",
    "print(cluster_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters_3 = kmeans(RFM_scaled, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert clusters to DataFrame with appropriate index and column names\n",
    "cluster_df = pd.DataFrame(cluster_less_6)\n",
    "\n",
    "\n",
    "cluster_df.index = RFM[:25000].index\n",
    "cluster_df.columns = ['Recency', 'Monetary', \n",
    "                      'Frequency', 'Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df.index.names = ['user_id']\n",
    "cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for snake plot\n",
    "cluster_melt = pd.melt(cluster_df.reset_index(),\n",
    "                       id_vars=['user_id', 'Cluster'],\n",
    "                       value_vars=['Recency',\n",
    "                                   'Frequency',\n",
    "                                   'Monetary'],\n",
    "                       var_name='Metric',\n",
    "                       value_name='Value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_melt['Cluster'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create snake plot\n",
    "# palette = ['powderblue', 'green','orange','purple','steelblue','grey']\n",
    "palette = 'colorblind'\n",
    "plt.figure(figsize=[5.6,3])\n",
    "sns.pointplot(x='Metric', y='Value', data=cluster_melt, hue='Cluster', \n",
    "              palette=palette)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Value')\n",
    "plt.yticks([])\n",
    "#plt.title('Six Customer Segments')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('snake_plot_5_clusters_less_data_head_25000_Av_R2.png', dpi=300, pad_inches=2.0)\n",
    "plt.savefig('snake_plot_5_clusters_less_data_head_25000_Av_R2.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threeD = plt.figure(figsize=[5.6,3]).gca(projection= '3d')\n",
    "threeD.scatter(cluster_df['Recency'],cluster_df['Frequency'],\n",
    "               cluster_df['Monetary'], \n",
    "               c = cluster_df['Cluster'],cmap='icefire_r')\n",
    "threeD.set_xlabel('Recency')\n",
    "threeD.set_ylabel('Frequency')\n",
    "threeD.set_zlabel('Monetary')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('threeD_cluster.png', dpi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the cluster data into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters_all_data = pd.DataFrame(cluster_labels)\n",
    "df_clusters_add = pd.DataFrame(labels)\n",
    "df_clusters_all_data = df_clusters_all_data.append(df_clusters_add).reset_index()\n",
    "df_clusters_all = df_clusters_all_data.drop(['index'],axis = 1)\n",
    "df_clusters_all = df_clusters_all.rename(columns={0:'Cluster'})\n",
    "df_clusters_all.to_csv('clustered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering the customers based on their RFM values\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import sklearn.metrics as ss\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale(RFM)\n",
    "\n",
    "clustering = KMeans(n_clusters = 5, random_state = 5)\n",
    "clustering.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_theme = np.array(['darkgray','lightsalmon','powderblue','green','yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = RFM.Frequency, y = RFM.Recency, c = color_theme[clustering.labels_])\n",
    "plt.title('K-Means classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = RFM.Monerary, y = RFM.Recency, c = color_theme[clustering.labels_])\n",
    "plt.title('K-Means classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = RFM.Monerary, y = RFM.Frequency, c = clustering.labels_)\n",
    "plt.title('K-Means classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench_k_means(estimator, name, data):\n",
    "    estimator.fit(data)\n",
    "    print('%-9s\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f'\n",
    "          % (name, estimator.inertia_,\n",
    "             metrics.homogeneity_score(y, estimator.labels_),\n",
    "             metrics.completeness_score(y, estimator.labels_),\n",
    "             metrics.v_measure_score(y, estimator.labels_),\n",
    "             metrics.adjusted_rand_score(y, estimator.labels_),\n",
    "             metrics.adjusted_mutual_info_score(y,  estimator.labels_),\n",
    "             metrics.silhouette_score(data, estimator.labels_,\n",
    "                                      metric='euclidean')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('quad_payload': conda)",
   "language": "python",
   "name": "python38364bitquadpayloadconda6ba0177791064be6b2b0b1160c45fe7d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
