{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 2\n",
    "Train and verify the two feature RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyRNN\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(data):\n",
    "    #calculate what counts as outlier\n",
    "    Q1 = np.quantile(data, 0.25)\n",
    "    Q3 = np.quantile(data, 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    data_without_fliers = np.copy(data)\n",
    "    data_without_fliers[data > Q3 + 1.5*IQR] = Q3 + 1.5*IQR\n",
    "    data_without_fliers[data < Q1 - 1.5*IQR] = Q1 - 1.5*IQR\n",
    "    \n",
    "    return data_without_fliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_pickle(\"df_test_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame.copy(df_val)\n",
    "results_df = df_val.drop(['max_days', \n",
    "                          'min_days',\n",
    "                          'days_since',\n",
    "                          't_5',\n",
    "                          't_4',\n",
    "                          't_3',\n",
    "                          't_2',\n",
    "                          't_1'], axis = 1)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create varaibles to store the results\n",
    "y_rrn1 = []\n",
    "\n",
    "r_regres = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the lenght\n",
    "original_df_len = df_val.shape[0]\n",
    "\n",
    "#two feature RRN\n",
    "y_rrn2 = []\n",
    "rnn_row_id = []\n",
    "i = 0\n",
    "for index, row in df_val[80000:].iterrows():\n",
    "    \n",
    "    \n",
    "    print (\"progress : \" , (index/original_df_len)*100)\n",
    "    \n",
    "    if i%10000 == 0:    \n",
    "        print (\"yee\")\n",
    "        name = \"out_rnn2_\" + str(i) + \".pkl\"\n",
    "        name1 = \"out_row_\" + str(i) + \".pkl\"\n",
    "        pd.DataFrame(y_rrn2).to_pickle(name)\n",
    "        pd.DataFrame(rnn_row_id).to_pickle(name1)\n",
    "    i +=1\n",
    "    \n",
    "    #read the data\n",
    "    x1 = np.array(row.product_seq[:-1])\n",
    "    x2 = np.array(row.days_since_seq)[1:-1]\n",
    "    x = np.array([x1,x2]).T\n",
    "    \n",
    "    #scale the data\n",
    "    scale_factor = x.max()\n",
    "    x_two_features = x/scale_factor\n",
    "    \n",
    "    #train the RNN\n",
    "    my_model = MyRNN.two_feature_RNN()\n",
    "    my_model.train(remove_outlier(x_two_features), \n",
    "                   n_epochs = 1000, lr= 0.01, weight_decay = 0.005)\n",
    "\n",
    "    #predict the future\n",
    "    predictions = my_model.predict(x_two_features)\n",
    "    \n",
    "    y_rrn2.append(predictions[-1]*scale_factor)\n",
    "    rnn_row_id.append([row.user_id, row.product_id])\n",
    "#     y = np.array([y1,y2]).T\n",
    "    \n",
    "#     print (index)\n",
    "#     print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['rnn_2'] != NaN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['rnn_2'][num_done:] = y_rrn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df.rnn_2.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle(\"rnn2_backup2.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
